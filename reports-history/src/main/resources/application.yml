spring :
  application :
    name : reports-history
  datasource :
    type : com.zaxxer.hikari.HikariDataSource
    url : ${DATASOURCE_URL:jdbc:postgresql://localhost:5432/lorem_ipsum_db}
    username : ${DATASOURCE_USERNAME:postgres}
    password : ${DATASOURCE_PASSWORD:postgres}
    driver-class-name : ${DATASOURCE_DRIVER:org.postgresql.Driver}
    hikari :
      pool-name : Hikari
      auto-commit : false
  jpa :
    hibernate :
      ddl-auto : none
      naming :
        physical-strategy : org.springframework.boot.orm.jpa.hibernate.SpringPhysicalNamingStrategy
        implicit-strategy : org.springframework.boot.orm.jpa.hibernate.SpringImplicitNamingStrategy
    open-in-view : true
    properties :
      hibernate.jdbc.time_zone : UTC
      hibernate.id.new_generator_mappings : true
      hibernate.connection.provider_disables_autocommit : true
      hibernate.cache.use_second_level_cache : true
      hibernate.cache.use_query_cache : true
      hibernate.generate_statistics : false
      # modify batch size as necessary
      hibernate.jdbc.batch_size : 25
      hibernate.order_inserts : true
      hibernate.order_updates : true
      hibernate.query.fail_on_pagination_over_collection_fetch : true
      hibernate.query.in_clause_parameter_padding : true
    show-sql : false
  devtools :
    add-properties : false
    restart :
      enabled : false
    livereload :
      enabled : false

  jackson :
    default-property-inclusion : NON_NULL
  lifecycle :
    timeout-per-shutdown-phase : ${TIMEOUT_PER_SHUTDOWN:20s}
  groovy :
    template :
      check-template-location : false

  kafka :
    consumer :
      bootstrap-servers : ${KAFKA_BOOTSTRAP_SERVERS:localhost:29092}
      auto-offset-reset : earliest
      properties :
        basic.auth.credentials.source : SASL_INHERIT
        security.protocol : ${KAFKA_SECURITY_PROTOCOL:PLAINTEXT}
        sasl.mechanism : SCRAM-SHA-512
        sasl.jaas.config : "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_USERNAME}\" password=\"${KAFKA_PASSWORD}\";"
        isolation.level : read_committed
      group-id : ${KAFKA_CONSUMERS_GROUP:reports-history}
    producer :
      bootstrap-servers : ${KAFKA_BOOTSTRAP_SERVERS:localhost:29092}
      value-serializer : org.springframework.kafka.support.serializer.JsonSerializer
      properties :
        basic.auth.credentials.source : SASL_INHERIT
        security.protocol : ${KAFKA_SECURITY_PROTOCOL:PLAINTEXT}
        sasl.mechanism : SCRAM-SHA-512
        sasl.jaas.config : "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_USERNAME}\" password=\"${KAFKA_PASSWORD}\";"
        spring.json.add.type.headers : false
    admin :
      properties :
        bootstrap.servers : ${KAFKA_BOOTSTRAP_SERVERS:localhost:29092}
        security.protocol : ${KAFKA_SECURITY_PROTOCOL:PLAINTEXT}
        sasl.mechanism : SCRAM-SHA-512
        sasl.jaas.config : "org.apache.kafka.common.security.scram.ScramLoginModule required username=\"${KAFKA_USERNAME}\" password=\"${KAFKA_PASSWORD}\";"

server :
  port : ${SERVER_PORT:8086}
  shutdown : graceful

logbook :
  exclude :
    - /actuator/**
    - /v3/**
    - /swagger-ui/**
    - /swagger-resources/**
    - /metrics
  filter :
    enabled : true
  format :
    style : json
  obfuscate :
    headers :
      - Authorization
      - X-Secret
    parameters :
      - access_token
      - password

logging :
  level :
    ROOT : INFO
    liquibase : INFO
management :
  server :
    add-application-context-header : true
  endpoints :
    enabled-by-default : false
    web :
      path-mapping :
        health : actuator/health
        prometheus : metrics
        info : info
      base-path : /
      exposure :
        include : health, prometheus, info
  endpoint :
    health :
      enabled : true
      show-details : always
    prometheus :
      enabled : true
    info :
      enabled : true

embedded :
  postgresql :
     enabled : false
     docker-image-version : 13.5
  kafka :
    enabled : false
    docker-image-version : 6.2.4


loremipsum :
  kafka :
    create-topics-on-startup : ${KAFKA_CREATE_TOPICS_ON_STARTUP:true}
    error-handling :
      dead-letter :
        retention : 1d
        suffix : .DLT
      backoff :
        initial-interval : 500ms
        max-interval : 2s
        max-retries : 4
        multiplier : 1.5
    consumer :
      threads : ${KAFKA_CONSUMER_THREADS:4}
    topics :
      words-processed :
        name : ${KAFKA_TOPIC_WORDS_PROCESSED:words.processed}
        partitions : ${KAFKA_TOPIC_PARTITIONS_WORDS_PROCESSED:4}
        retention : ${KAFKA_TOPIC_RETENTION_WORDS_PROCESSED:30m}
